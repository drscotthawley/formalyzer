{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bac34fc",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    ">Core routines, and also where the main `formalyzer` workflow is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac124dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00bc39",
   "metadata": {
    "time_run": "2025-11-26T21:26:22.066605+00:00"
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169af79",
   "metadata": {},
   "source": [
    "## Basic File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a1146",
   "metadata": {
    "time_run": "2025-11-27T00:26:39.766021+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import os \n",
    "\n",
    "def read_text_file(filename:str) -> list:\n",
    "    \"generic, read any text file\" \n",
    "    with open(os.path.expanduser(filename)) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde62b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_recc_info(info_file:str) -> list:\n",
    "    \"read a text file of info on the reviewer\" \n",
    "    return read_text_file(info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93a55d",
   "metadata": {
    "time_run": "2025-11-27T00:26:46.290009+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reccomender Name: Teacher Person \n",
      "Title: Professor of Cleverness \n",
      "\n",
      "Address: \n",
      "Department of Curiosities\n",
      "Generic University \n",
      "1337 Generic Pl. \n",
      "Springfield, WA 31416 USA\n",
      "\n",
      "Phone: 555-123-1337\n",
      "Email: teacher.person@generic.edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recc_info = read_recc_info(\"../example/recc_info.txt\") \n",
    "print(recc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3251b0d",
   "metadata": {
    "time_run": "2025-11-27T00:26:48.594438+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_urls_file(urls_file:str) -> list:\n",
    "    \"read a text file where each line is a url of a submission site\" \n",
    "    text = read_text_file(urls_file)\n",
    "    return [line for line in text.splitlines() if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb7a57",
   "metadata": {
    "time_run": "2025-11-27T00:26:33.067888+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 urls in list\n",
      "1 of 1: http://localhost:8000/sample_form.html\n"
     ]
    }
   ],
   "source": [
    "urls = read_urls_file(\"../example/sample_urls.txt\") \n",
    "print(f\"{len(urls)} urls in list\")\n",
    "for i, url in enumerate(urls): \n",
    "    print(f\"{i+1} of {len(urls)}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d0c0a",
   "metadata": {
    "time_run": "2025-11-26T21:30:45.307164+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from pypdf import PdfReader\n",
    "import logging\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "def read_pdf_text(pdf_file):\n",
    "    reader = PdfReader(os.path.expanduser(pdf_file))\n",
    "    return \"\\n\".join(page.extract_text() for page in reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147ccb2",
   "metadata": {
    "time_run": "2025-11-26T21:31:06.021867+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dear Graduate Admissions Committee,  I am writing to recommend Student Person for admission to your graduate program. Having worked closely with them for two years in both teaching and research capacities, I can say they are among the strongest students I have encountered in over a decade of academic work.  Student Person took several of my advanced courses — Quantum Rollercoasters, Physics of Impossible Machines, and a seminar on Neural Networks for Curious Minds. They also worked with me on an independent research project. In every setting, they showed sharp intellectual ability, creative thinking, and real persistence. Their coursework went beyond surface-level competence; they clearly grasped the deeper principles at play. As a researcher, they brought fresh perspectives while staying receptive to guidance.  What stands out most is their dependability. They consistently met deadlines and produced high-quality work. During our independent project, they actually moved ahead of schedule, diving into advanced material sooner than expected. That kind of self-direction is uncommon and bodes well for graduate study.  They are also an effective communicator — clear and organized in writing, articulate in discussion. They collaborate well, contributing to group dynamics without dominating them.  Overall, I would rate Student Person as outstanding across the board: intellectual ability, research aptitude, writing, and professional potential. Their creativity, interpersonal skills, and motivation are all exceptional. I am confident they will be a valuable addition to your program.  Feel free to reach out if you would like to discuss further.  Please feel free to contact me if you require any additional information.  Sincerely,    Teacher Person, Ph.D. Professor of Cleverness  \n",
      "          DEPARTMENT of  CURIOSITIES \n",
      "1337 Generic Pl Springfield, WA 31415-2654  phone 555-123-1337 fax  555-123-5555 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "letter_text = read_pdf_text(\"../example/sample_letter.pdf\")\n",
    "print(letter_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f552d32",
   "metadata": {},
   "source": [
    "## Parsing HTML (Form) Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63694d",
   "metadata": {
    "time_run": "2025-11-27T00:28:50.190062+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from bs4 import BeautifulSoup\n",
    "import json, re\n",
    "\n",
    "\n",
    "def scrape_form_fields(html):\n",
    "    \"\"\"Extract all fillable form fields from HTML\"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    fields = []\n",
    "    for inp in soup.find_all(['input', 'select', 'textarea']):\n",
    "        field_id = inp.get('id') or inp.get('name', '')\n",
    "        if not field_id: continue\n",
    "        field_type = inp.get('type', inp.name)\n",
    "        if field_type in ['hidden', 'submit', 'button']: continue\n",
    "        \n",
    "        label = soup.find('label', {'for': field_id})\n",
    "        label_text = label.get_text(strip=True) if label else ''\n",
    "        current_value = inp.get('value', '')\n",
    "        \n",
    "        options = None\n",
    "        if inp.name == 'select':\n",
    "            options = [opt.get_text(strip=True) for opt in inp.find_all('option') if opt.get_text(strip=True)]\n",
    "        \n",
    "        fields.append({\n",
    "            'id': field_id, 'label': label_text, 'type': field_type,\n",
    "            'options': options, 'prefilled': bool(current_value and field_type not in ['radio','checkbox'] and inp.name != 'select')\n",
    "        })\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae472c2",
   "metadata": {
    "collapsed": true,
    "time_run": "2025-11-27T00:31:01.244402+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['applicant_name',\n",
       " 'applicant_message',\n",
       " 'ferpa_waiver',\n",
       " 'ferpa_waiver',\n",
       " 'program',\n",
       " 'discipline',\n",
       " 'prefix',\n",
       " 'first_name',\n",
       " 'middle_name',\n",
       " 'last_name',\n",
       " 'organization',\n",
       " 'title',\n",
       " 'phone',\n",
       " 'email',\n",
       " 'addr1',\n",
       " 'addr2',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip',\n",
       " 'country',\n",
       " 'months_known',\n",
       " 'years_range',\n",
       " 'capacity',\n",
       " 'rating_intellectual',\n",
       " 'rating_scientific',\n",
       " 'rating_research',\n",
       " 'rating_prev_work',\n",
       " 'rating_lab',\n",
       " 'rating_oral_1',\n",
       " 'rating_oral_2',\n",
       " 'rating_oral_3',\n",
       " 'rating_oral_4',\n",
       " 'rating_oral_5',\n",
       " 'rating_oral_6',\n",
       " 'rating_writing_1',\n",
       " 'rating_writing_2',\n",
       " 'rating_writing_3',\n",
       " 'rating_writing_4',\n",
       " 'rating_writing_5',\n",
       " 'rating_writing_6',\n",
       " 'rating_originality_1',\n",
       " 'rating_originality_2',\n",
       " 'rating_originality_3',\n",
       " 'rating_originality_4',\n",
       " 'rating_originality_5',\n",
       " 'rating_originality_6',\n",
       " 'rating_perseverance_1',\n",
       " 'rating_perseverance_2',\n",
       " 'rating_perseverance_3',\n",
       " 'rating_perseverance_4',\n",
       " 'rating_perseverance_5',\n",
       " 'rating_perseverance_6',\n",
       " 'rating_independence_1',\n",
       " 'rating_independence_2',\n",
       " 'rating_independence_3',\n",
       " 'rating_independence_4',\n",
       " 'rating_independence_5',\n",
       " 'rating_independence_6',\n",
       " 'rating_interpersonal_1',\n",
       " 'rating_interpersonal_2',\n",
       " 'rating_interpersonal_3',\n",
       " 'rating_interpersonal_4',\n",
       " 'rating_interpersonal_5',\n",
       " 'rating_interpersonal_6',\n",
       " 'rating_work_ethic_1',\n",
       " 'rating_work_ethic_2',\n",
       " 'rating_work_ethic_3',\n",
       " 'rating_work_ethic_4',\n",
       " 'rating_work_ethic_5',\n",
       " 'rating_work_ethic_6',\n",
       " 'rating_suitability_1',\n",
       " 'rating_suitability_2',\n",
       " 'rating_suitability_3',\n",
       " 'rating_suitability_4',\n",
       " 'rating_suitability_5',\n",
       " 'rating_suitability_6',\n",
       " 'phd_fit',\n",
       " 'capacity_text',\n",
       " 'letter_upload',\n",
       " 'signature_name']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = read_text_file(\"../example/sample_form.html\") \n",
    "fields = scrape_form_fields(html) \n",
    "[f['id'] for f in fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e0d4c",
   "metadata": {},
   "source": [
    "## LLM Usage\n",
    "Next we prompt the LLM to figure out which form fields apply, and how: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9577d05",
   "metadata": {
    "time_run": "2025-11-26T22:09:48.705983+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from claudette import Chat\n",
    "\n",
    "def get_field_mappings(fields, recc_info, letter_text, model=\"claude-sonnet-4-20250514\", debug=False):\n",
    "    \"\"\"Use LLM to map recommender info and letter to form fields\"\"\"\n",
    "    prompt = f\"\"\"You are filling out a graduate school recommendation form.\n",
    "\n",
    "RECOMMENDER INFO:\n",
    "{recc_info}\n",
    "\n",
    "RECOMMENDATION LETTER:\n",
    "{letter_text}\n",
    "\n",
    "FORM FIELDS TO FILL:\n",
    "{json.dumps([f for f in fields if not f['prefilled']], indent=2)}\n",
    "\n",
    "For each field, provide the field ID and value to fill. For dropdowns, pick from the options listed.\n",
    "Pay attention to groups of radio buttons (grouped via div or similar id prefixes) as they may form likert scales.\n",
    "Return as JSON array: [{{\"id\": \"form_xxx\", \"value\": \"...\"}}]\n",
    "\"\"\"\n",
    "    chat = Chat(model=model)\n",
    "    if debug: print(f\"  Prompt length is {len(prompt)} characters\")\n",
    "    response = chat(prompt)\n",
    "    json_match = re.search(r'```json\\s*(.*?)\\s*```', response.content[0].text, re.DOTALL)\n",
    "    return json.loads(json_match.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f1fb3",
   "metadata": {},
   "source": [
    "## Filling in the Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce76a9",
   "metadata": {
    "time_run": "2025-11-27T00:23:03.947356+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "async def get_element_info(page, field_id):\n",
    "    \"given an id or a name, find the element on the page and get its info\"\n",
    "    elem = page.locator(f'#{field_id}, [name=\"{field_id}\"]')\n",
    "    await elem.wait_for(timeout=1000) # 1 second. default timeout for non-found fields is 30 seconds.\n",
    "    tag = await elem.evaluate('el => el.tagName.toLowerCase()')\n",
    "    input_type = await elem.evaluate('el => el.type')\n",
    "    return elem, tag, input_type\n",
    "\n",
    "\n",
    "async def should_skip(elem, tag, input_type, skip_prefilled) -> bool:\n",
    "    \"should we fill in this element? Not if there's already a value there.\"\n",
    "    if skip_prefilled and tag != 'select' and input_type != 'radio':\n",
    "        current = await elem.input_value()\n",
    "        if current: return True # there's already a value provided, skip it\n",
    "    return False\n",
    "\n",
    "\n",
    "async def fill_element(elem, tag, input_type, field_id, value):\n",
    "    \"actually fill in this element\"\n",
    "    if tag == 'select':\n",
    "        await elem.select_option(label=value)\n",
    "    else:\n",
    "        if input_type == 'radio':\n",
    "            print(f\"  Clicking radio button {field_id} with value {value}\")\n",
    "            await elem.click()\n",
    "        else:\n",
    "            await elem.fill(value)   \n",
    "\n",
    "\n",
    "async def fill_form(page, mappings, skip_prefilled=True, debug=False):\n",
    "    \"\"\"Fill form fields using Playwright\"\"\"\n",
    "    results = {'filled': [], 'skipped': [], 'errors': []}\n",
    "    for i, item in enumerate(mappings):\n",
    "        field_id, value = item['id'], item['value']\n",
    "        if debug: print(f\"Mapping {i+1} of {len(mappings)}:  Processing {field_id}...\")\n",
    "        try:\n",
    "            elem, tag, input_type = await get_element_info(page, field_id)\n",
    "            \n",
    "            if await should_skip(elem, tag, input_type, skip_prefilled):\n",
    "                results['skipped'].append(field_id)\n",
    "                continue\n",
    "            \n",
    "            await fill_element(elem, tag, input_type, field_id, value)\n",
    "            results['filled'].append(field_id)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error filling {field_id}: {e}\")\n",
    "            results['errors'].append({'id': field_id, 'error': str(e)[:50]})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def upload_recommendation(page, file_path):\n",
    "    \"\"\"Upload the recommendation PDF\"\"\"\n",
    "    file_input = page.locator('input[type=\"file\"]').first\n",
    "    await file_input.set_input_files(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca22956",
   "metadata": {
    "time_run": "2025-11-26T23:47:56.847871+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "async def process_url(page, url, recc_info, letter_text, pdf_path, debug=False):\n",
    "    \"\"\"Process a single recommendation URL\"\"\"\n",
    "    await page.goto(url)\n",
    "    html = await page.content()\n",
    "    \n",
    "    if debug: print(\"Scraping form fields\")\n",
    "    fields = scrape_form_fields(html)\n",
    "    if debug: print(f\"Found {len(fields)} fields\")\n",
    "    \n",
    "    if debug: print(\"Calling LLM to get field mappings\")\n",
    "    mappings = get_field_mappings(fields, recc_info, letter_text, debug=debug)\n",
    "    if debug: print(f\"Got {len(mappings)} mappings from LLM\")\n",
    "    \n",
    "    if debug: print(\"Filling in form\")\n",
    "    results = await fill_form(page, mappings, debug=debug)\n",
    "    if debug: print(f\"Filled: {len(results['filled'])}, Errors: {len(results['errors'])}\")\n",
    "    \n",
    "    if debug: print(\"Uploading PDF\") \n",
    "    await upload_recommendation(page, pdf_path)\n",
    "    if debug: print(\"Uploaded PDF\")\n",
    "    \n",
    "    input(\"Review the form, then press Enter to continue to next URL (or Ctrl+C to stop)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c2345",
   "metadata": {},
   "source": [
    "# `formalyzer` CLI script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aeb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_info(recc_info:str, pdf_path:str, urls:str):\n",
    "    \"parse CLI args and read input files\"\n",
    "    recc_info, pdf_path = [os.path.expanduser(_) for _ in [recc_info, pdf_path]]\n",
    "    assert os.path.exists(recc_info), f\"File not found: {recc_info}\"\n",
    "    assert os.path.exists(pdf_path), f\"File not found: {pdf_path}\"\n",
    "    recc_info = read_recc_info(recc_info) \n",
    "    letter_text = read_pdf_text(pdf_path)\n",
    "    if os.path.exists(os.path.expanduser(urls)): \n",
    "        print(f\"File {urls} exists. Reading.\")\n",
    "        urls = read_urls_file(urls)\n",
    "    else: \n",
    "        print(f\"No file {urls}. Treating it as a single url\") \n",
    "        urls = [urls]\n",
    "    return recc_info, letter_text, urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95243e5",
   "metadata": {
    "time_run": "2025-11-26T23:48:09.120262+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "async def setup_browser():\n",
    "    \"\"\"Connect to Chrome with remote debugging\"\"\"\n",
    "    from playwright.async_api import async_playwright\n",
    "\n",
    "    pw = await async_playwright().start()\n",
    "    browser = await pw.chromium.connect_over_cdp(\"http://localhost:9222\")\n",
    "    page = await browser.new_page()\n",
    "    return pw, browser, page\n",
    "\n",
    "\n",
    "async def run_formalyzer(recc_info, letter_text, urls, pdf_path, debug=False):\n",
    "    \"\"\"Main async workflow\"\"\"\n",
    "    pw, browser, page = await setup_browser()\n",
    "    try:\n",
    "        for i, url in enumerate(urls):\n",
    "            if not url.strip(): continue  # skip empty urls\n",
    "            print(f\"\\nURL {i+1} of {len(urls)}: {url}\")\n",
    "            await process_url(page, url, recc_info, letter_text, pdf_path, debug=debug)\n",
    "    finally:\n",
    "        await browser.close()\n",
    "        await pw.stop()\n",
    "\n",
    "\n",
    "from fastcore.script import call_parse\n",
    "import asyncio\n",
    "\n",
    "@call_parse\n",
    "def main(recc_info:str, pdf_path:str, urls:str, debug:bool=False):\n",
    "    assert os.environ.get('ANTHROPIC_API_KEY'), \"Please set ANTHROPIC_API_KEY environment variable\" # used by Claudette\n",
    "    recc_info, letter_text, urls = read_info(recc_info, pdf_path, urls)\n",
    "    if debug:\n",
    "        print(\"recc_info =\\n\", recc_info)\n",
    "        print(\"letter_text =\\n\", letter_text)\n",
    "        print(\"urls =\\n\", urls)\n",
    "    \n",
    "    # Run the async workflow\n",
    "    asyncio.run(run_formalyzer(recc_info, letter_text, urls, pdf_path, debug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(\"~/recc_info.txt\", \"~/recc_letter.pdf\",\"~/recc_urls.txt\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
